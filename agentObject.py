import os
import dspy
from datetime import datetime, timezone
from dotenv import load_dotenv
from dbObject import dbObject

from dspy.primitives.assertions import assert_transform_module, backtrack_handler
from dspy import Suggest


class Agent():
    def __init__(self, network_id: str, agent_id=None, db: dbObject=None):
        if db is None:
            raise ValueError("Database object cannot be None.")
        self.db = db
        self.network_id = network_id

        if network_id is None:
            raise ValueError("Network ID cannot be None.")

        self.agent_id = agent_id
        
        self._setup_language_model()
        self.user_chat_module = UserChatModule()
        self.instructions = self.db.get_instructions(self.agent_id)
        self.chat_history = []

    def _setup_language_model(self):
        self.turbo = dspy.OpenAI(model="gpt-3.5-turbo", max_tokens=2000, model_type="chat", temperature=0.8)
        dspy.settings.configure(lm=self.turbo, trace=[])
        print("Language model configured successfully.")

######################## USER CHAT ########################

########### need to completely rework this for 
    # just responds to a message
    def handle_user_chat(self, message):
        user_response = self.user_chat_module(prompt=message, instructions=self.instructions)
        self.chat_history.append({"user": message, "agent": user_response["answer"]})
    
        return user_response["answer"]


######################### AGENTS CHAT ########################
        
    def handle_agent_interaction(self, partner_agent_id):

        # creating a chat environment
        environment = EnvironmentGenerator().forward()

        print("*"*50)
        print(f"Generated chat environment: {environment}")
        print("*"*50)

        # init DSPy chat modules
        home_agent = assert_transform_module(AgentChatModule(self.db, self.agent_id, self.chat_history, environment=environment), backtrack_handler) # active suggestions (used in relevance check)
        away_agent = assert_transform_module(AgentChatModule(self.db, self.agent_id, self.chat_history, environment=environment), backtrack_handler) # active suggestions (used in relevance check)

        
        # determine number of interactions
        num_interactions = IterationCounter(self.db).forward(self.agent_id, partner_agent_id, environment)

        print(f"Number of initial interactions: {num_interactions}")

        # initial prompt to start the conversation
        # TODO: logic could be added for the initial prompt to be generated by what's in the memory retrieval, or maybe what's most recent
        init_prompt = "Hey, talk to me!"

        def run_interactions(num_interactions):
            for i in range(num_interactions):
                if i == 0:
                    # home responds to init prompt
                    home_retrieved_memories = str(self.db.get_agent_memory(self.agent_id, init_prompt))
                    home_response = home_agent.forward(prompt=init_prompt, instructions=self.instructions, retrieved_memories=home_retrieved_memories)

                    # away responds to home's response
                    away_retrieved_memories = str(self.db.get_agent_memory(partner_agent_id, home_response['answer']))
                    away_response = away_agent.forward(prompt=home_response['answer'], instructions=self.instructions, retrieved_memories=away_retrieved_memories)
                else:
                    # home responds to away's response
                    home_retrieved_memories = str(self.db.get_agent_memory(self.agent_id, away_response['answer']))
                    home_response = home_agent.forward(prompt=away_response['answer'], instructions=self.instructions, retrieved_memories=home_retrieved_memories)

                    # away responds to home's response
                    away_retrieved_memories = str(self.db.get_agent_memory(partner_agent_id, home_response['answer']))
                    away_response = away_agent.forward(prompt=home_response['answer'], instructions=self.instructions, retrieved_memories=away_retrieved_memories)

        # Run initial interactions
        run_interactions(num_interactions)

        # Determine if the conversation should be extended
        end_conversation = ConversationEnder().forward(self.chat_history, environment, num_interactions)
        if end_conversation == "No":
            additional_interactions = num_interactions // 2
            run_interactions(additional_interactions)

        # Summarize chat history (to store in memory)
        summarizer = ChatHistorySummarizer()
        interaction_summary = summarizer(self.agent_id, self.chat_history)

        # Check toxicity of the chat history
        formatted_chat_history = home_agent.format_chat_history() # make it a str
        toxicity_checker = ToxicityChecker(self.db)
        is_toxic = toxicity_checker(formatted_chat_history, self.agent_id)

        # Store summary in memory
        self.db.add_agent_data(self.agent_id, interaction_summary, is_toxic)

        # Testing
        print(f"Chat history: \n{formatted_chat_history}")
        print(f"Chat history summary: \n{interaction_summary}")

        return interaction_summary


########################## DSPY CLASSES ##########################
    
##################### AGENT CHAT MODULES #####################
class AgentChatModule(dspy.Module):
    class AgentChatSignature(dspy.Signature):
        """
        Exchange information with another agent, following the instructions provided. Do not make up any information or experiences.
        Find commonalities and relevant things in your memory retrieval based on what the other agent asks you. The conversation takes place in the environment provided.
        """
        guidelines = dspy.InputField(desc="User-set guidelines for you follow during social interactions.")
        prompt = dspy.InputField(desc="A message from the other agent.")
        environment = dspy.InputField(desc="The environment for the conversation among agents to take place in.")
        memory_retrieval = dspy.OutputField(desc="Retrieved memory based on the prompt.")
        answer = dspy.OutputField(desc="A response to the other agent.")

    def __init__(self, db, agent_id, chat_history, environment=None): # ?Maybe have a default environment?
        self.db = db
        self.environment = environment
        self.agent_id = agent_id
        self.chat_history = chat_history # stored in the class so we can call it outside of the module

    def forward(self, prompt, instructions, retrieved_memories, environment):
        # add some module here for interpeting the memories based on how we store their summaries. Picking the ones relevant to the conversation to compose context info string to be added to the prompt.

        agent_chat_response = dspy.ChainOfThought(self.AgentChatSignature)(
            guidelines=instructions,
            environment=environment,
            prompt=prompt,
            memory_retrieval=retrieved_memories
        )

        # check relevance of the response
        is_relevant = RelevanceChecker()

        # retry logic for relevance check
        Suggest(is_relevant(memory_context=retrieved_memories, previous_chat_msg=agent_chat_response['answer']), "Your response should be more relevant to the memories or previous chat message.")

        # Add the latest response in the chat history
        self.append_chat_history(prompt, agent_chat_response['answer'])

        return agent_chat_response

    def append_chat_history(self, prompt, response):
        timestamp = datetime.now(timezone.utc).isoformat()
        chat_entry = {
            "timestamp": timestamp,
            "agent_id": self.agent_id,
            "prompt": prompt,
            "response": response
        }
        self.chat_history.append(chat_entry)

    # for better interpretation during summary
    def format_chat_history(self):
        formatted_history = []
        for entry in self.chat_history:
            formatted_entry = f"Timestamp: {entry['timestamp']}\n"
            formatted_entry += f"Agent {entry['agent_id']}\nPrompt: {entry['prompt']}\n"
            formatted_entry += f"Response: {entry['response']}\n"
            formatted_entry += "-" * 50
            formatted_history.append(formatted_entry + "\n")
        return "\n".join(formatted_history)
    

##################### EVALUATIONS/CHECKERS #####################
class RelevanceChecker(dspy.Module):
    class RelevanceCheckerSignature(dspy.Signature):
        """
        You are a checker of relevance for an agent engaged in a conversation.
        Before the agent sends a response, you will check if it is based in facts from memory context, or the previous chat message. 
        If a text string contains hallucinations not based in fact or conversation return 'No', otherwise return 'Yes'.
        """

        memory_context = dspy.InputField(desc="the knowledge domain used in creating it's response.")
        previous_chat_msg = dspy.InputField(desc="Text string to check for relevance.")
        is_relevant = dspy.OutputField(desc="Yes or No")

    def forward(self, memory_context, previous_chat_msg):
        result = dspy.ChainOfThought(self.RelevanceCheckerSignature)(
            memory_context=memory_context,
            previous_chat_msg=previous_chat_msg,
        ).is_relevant

        if 'Yes' in result: print("The response is relevant.") 
        else: print("The response is not relevant.")
        
        return 'Yes' in result        

class ToxicityChecker(dspy.Module):
    class ToxicityCheckerSignature(dspy.Signature):
        """
        Check the toxicity of chat history and return 'Yes' if contains anything deemed as toxic by the settings, otherwise return 'No'.
        Chat history should not include anything that is off limits according to the toxicity settings.
        """
        toxicity_settings = dspy.InputField(desc="User settings for what is considered toxic.")
        chat_history = dspy.InputField(desc="Chat history to check for toxicity")
        in_context_prompt = dspy.InputField(desc="In-context prompt for the agent")
        answer = dspy.OutputField(desc="Yes or No")

    def __init__(self, db: dbObject):
        self.db = db

    def forward(self, chat_history, home_agent_id):
        # call toxicity settings from db
        toxicity_settings = self.db.get_toxicty_settings(home_agent_id)

        rationale_type = dspy.OutputField(
            prefix="Reasoning: Let's think step by step in order to",
            desc="Check if the chat history contains anything that the user settings consider toxic.",
        )

        result = dspy.ChainOfThought(self.ToxicityCheckerSignature, rationale_type=rationale_type)(
            toxicity_settings=toxicity_settings,
            chat_history=chat_history,
        ).answer

        # print(result)
        return 'Yes' in result

    # I'm thinking we should create another tag like the toxicity flag, but for positive things. Like if it finds anything highly relevant gets a good tag. 


# * Conversation Ending Module(s)

# * Order of execution
# 1. EnvironmentGenerator
# 2. IterationCounter
# 3. ConversationEnder

# module to create a random environment for the conversation
class EnvironmentGenerator(dspy.Module):
    class EnvironmentGeneratorSignature(dspy.Signature):
        """
        Generate a random environment for the agents to have a conversation in. The environment should be a place where the agents can interact with each other.
        """
        environment = dspy.OutputField(desc="A random environment for the conversation.")
        example = dspy.Example(environment="A coffee shop with a jazz band playing in the background and agents sitting (conversing) at a table.")

    def forward(self):
        environment = dspy.ChainOfThought(self.EnvironmentGeneratorSignature)().environment
        return environment

# module to determine number of interactions for the conversation
class IterationCounter(dspy.Module):
    class IterationCounterSignature(dspy.Signature):
        """
        Based on the environment and agent settings determine average number of interactions that should occur in a conversation.
        """
        # ?Not sure if we should be using agent memories or just the settings for this part.
        agent_settings1 = dspy.InputField(desc="First agent settings for the conversation.")
        agent_settings2 = dspy.InputField(desc="Second agent settings for the conversation.")
        environment = dspy.InputField(desc="The environment for the conversation among agents to take place in.")
        num_interactions = dspy.OutputField(desc="The number of interactions between agents in the conversation.", type=int)

        def __init__(self, db):
            self.db = db

        def forward(self, agent_id1, agent_id2, environment):
            agent_settings1 = self.db.get_agent_settings(agent_id1)
            agent_settings2 = self.db.get_agent_settings(agent_id2)

            # logic to determine number of interactions
            result = dspy.ChainOfThought(self.IterationCounterSignature)(
                agent_settings1=agent_settings1,
                environment=environment,
                agent_settings2=agent_settings2
            ).num_interactions

            return result
            

# module to determine number of interactions for the conversation
class ConversationEnder(dspy.Module):
    class ConversationEnderSignature(dspy.Signature):
        """
        Determine if the conversation should end based on the environment, chat history, and number of already executed interactions.
        """

        chat_history = dspy.InputField(desc="The chat history to be considered for ending the conversation between agents.")
        environment = dspy.InputField(desc="The environment for the conversation among agents to take place in.")
        end_conversation = dspy.OutputField(desc="Yes or No")
        # passing in the same value from the IterationCounter module
        num_interactions = dspy.InputField(desc="The number of interactions between agents in the conversation.", type=int)
        # ?Maybe we should add a score field to this signature to determine the overall tone and content of the conversation.
        # !score = dspy.OutputField(desc="The score of the conversation.", prefix="Reasoning: Let's think step by step to evaluate the overall tone and content of the conversation.")

        def forward(self, chat_history, environment, num_interactions):
            # logic to determine if the conversation should end
            result = dspy.ChainOfThought(self.ConversationEnderSignature)(
                num_interactions=num_interactions,
                chat_history=chat_history,
                environment=environment
            ).end_conversation

            return result


##################### USER MODULES #####################

# handles casual chat with the user
class UserChatModule(dspy.Module):
    class UserChatSignature(dspy.Signature):
        """Your task is to be a casual texting buddy of the user, texting with abbreviations and common slang. You can ask questions, provide answers, or just chat. You must follow the settings/instructions given to you."""
        guidelines = dspy.InputField(desc="User-set guidelines for the agent to follow during social interactions.")
        prompt = dspy.InputField()
        answer = dspy.OutputField(desc="A response to the user.")
        update_command = dspy.OutputField(desc="Command to update settings, if detected. Optional")
    
    def forward(self, prompt, instructions):
        # default casual chat response
        response = dspy.ChainOfThought(self.UserChatSignature)(guidelines=instructions, prompt=prompt).answer
        return {"answer": response}
    
        # for now, we'll streamline setting instructions, and toxicity_settings.
            # they can be set via their endpoints/dbObject methods
            # later, we can make them also updateable via the chat, by adding modules/checks here. For now, keep it simple stupid (KISS)
            # self.db.set_instructions(self.agent_id, instructions)
            # self.db.set_toxicity_settings(self.agent_id, toxicity_settings)
    

##################### CHAT HISTORY SUMMARIZER #####################
class ChatHistorySummarizer(dspy.Module):
    class ChatHistorySummarySignature(dspy.Signature):
        """
        Summarize the chat history with very descriptive information about what was shared. You are writing a one paragraph briefing for someone when someone asks you about the same topic.
        """
        chat_history = dspy.InputField(desc="The chat history to be summarized.")
        summary = dspy.OutputField(desc="A descriptive summary of the chat history.")
        # I really think we should include some examples of the format we want them to be stored in. They should include things like the date, away_agent_id, etc. This will be decided by how we interpret it on the recall side.
        # the module that turns the memories into conversation specific context should be able to interpret the format of the summary correctly.
        
    def forward(self, home_agent_id, chat_history_list):
        away_agent_id = chat_history_list[0]['agent_id'] if chat_history_list[0]['agent_id'] != home_agent_id else chat_history_list[1]['agent_id']
        rationale_type = dspy.OutputField(
            prefix="Reasoning: Let's think step by step in order to",
            desc=f"accurately summarize the chat history with very descriptive information about what was shared. I talked to {away_agent_id} about...",
        )

        chat_history_str = ""
        for item in chat_history_list:
            label = 'Me' if item['agent_id'] == home_agent_id else f'Agent {item["agent_id"]}'
            prompt_label = f'{label}: {item["prompt"]}' if label != 'Me' else label
            chat_history_str += f"{prompt_label}\n{label}: {item['response']}\n\n"


        response = dspy.ChainOfThought(self.ChatHistorySummarySignature, rationale_type=rationale_type)(
            chat_history=chat_history_str
        ).summary

        return response